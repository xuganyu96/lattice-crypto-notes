\section{Hard lattice problems and best known solutions}
We begin the discussion of hard lattice problems by defining two such problems. Unless otherwise specified, the Euclidean norm is used.

\begin{definition}
    Given a lattice $\mathcal{L}(B)$ spanned by basis $B$ and a norm $\Vert \cdot \Vert \rightarrow \mathbb{R}$, the \textbf{shortest vector problem} asks to find the shortest non-zero vector $\mathbf{v} \in \mathcal{L}(B)$
\end{definition}

The norm of the shortest non-zero vector is called the \textbf{minimum distance} and is denoted by $\lambda(\mathcal{L})$. Where the lattice is unambiguous we simply denote the minimum distance by $\lambda$.

\begin{definition}
    Given a lattice $\mathcal{L}(B)$, a norm, and some target vector $\mathbf{t}$ in the same vector space as the lattice, the \textbf{closest vector problem} asks to find a lattice point $\mathbf{v} \in \mathcal{L}$ that minimizes $\Vert \mathbf{t} - \mathbf{v}\Vert$
\end{definition}

There are two main parameters that affect the difficulty of SVP and CVP. The first is the number of dimensions $n$: the higher the number of dimension, the harder it is to find the shortest vector and/or the closest vector. The second is the orthogonality and/or the length of the basis. Intuitively, orthogonality and length are inversely related because the determinant of the lattice is invariant with respect to the choice of basis: higher orthogonality automatically implies shorter lengths. The more skewed the choice of basis, the more difficult it is to solve SVP/CVP.

\subsection{Minimum distance and orthogonalized basis}
The minimum distance of a lattice is bounded below by the shortest orthogonalized basis:

\begin{theorem}
    Given lattice $\mathcal{L}(B)$ with basis $B = [\mathbf{b}_1, \ldots, \mathbf{b}_n]$ and its Gram-Schmidt orthogonalization $B^\ast = [\mathbf{b}_1^\ast, \ldots, \mathbf{b}_n^\ast]$,

    $$
    \lambda \geq \min_{1 \leq i \leq n} \Vert \mathbf{b}_i^\ast \Vert
    $$
\end{theorem}

To prove this lower bound, we split the lattice $\mathcal{L}(B)$ into two partitions: the subset of lattice points generated by the sub-basis $B^\prime = [\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{n-1}]$ and the subset of lattice points whose has non-zero coefficient for the last base vector $\mathbf{b}_n$:

$$
\mathcal{L}(B) = 
\mathcal{L}(B^\prime) 
\cup \{B\mathbf{x} \mid \mathbf{x} \in \mathbb{Z}^n, x_n \neq 0\}
$$

Then, the minimum distance of $\mathcal{L}(B)$ is the minimum between the minimum distance of each subset. While we don't know the exact minimum distance of the second partition, we do know that such minimum distance must not be less than $\Vert \mathbf{b}_n^\ast \Vert$:
$$
\begin{aligned}
\Vert B\mathbf{x} \Vert^2 &= \Vert \sum_{i=1}^n\mathbf{b}_i x_i \Vert^2 \\
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + \mathbf{b}_nx_n \Vert^2 \\
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + (\mathbf{b}_n^* + \sum_{j<n}\mu_{j, n}\mathbf{b}_j^\ast)x_n \Vert^2 \\
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + (\sum_{j<n}\mu_{j, n}\mathbf{b}_j^\ast) x_n  + \mathbf{b}_n^\ast x_n\Vert^2 \\
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + (\sum_{j<n}\mu_{j, n}\mathbf{b}_j^\ast) x_n \Vert^2 + \Vert \mathbf{b}_n^\ast x_n \Vert^2 \\
&\geq \Vert \mathbf{b}_n^\ast x_n \Vert^2 \\
&\geq \Vert \mathbf{b}_n^\ast \Vert^2
\end{aligned}
$$

On the other hand, the minimum distance of the first partition is simply the minimum distance of the sub-lattice. Therefore we've obtained a recursive relationship that can be repeatedly applied $n$ times:

$$
\begin{aligned}
\lambda(\mathcal{L}(B)) 
&\geq \min(\lambda(\mathcal{L}([\mathbf{b}_i]_{i=1}^{n-1})), \Vert \mathbf{b}_n^\ast \Vert) \\
&\geq \min(
    \min(
        \lambda(\mathcal{L}([\mathbf{b}_i]_{i=1}^{n-2})), 
        \Vert \mathbf{b}_{n-1}^\ast \Vert
    )
    , \Vert \mathbf{b}_n^\ast \Vert
) \\
& \ldots \\
&\geq \min_{1 \leq i \leq n}(\Vert \mathbf{b}_i^\ast\Vert)
\end{aligned}
$$
$\blacksquare$

\subsection{Reduced lattice basis}
At the time of this survey, the best algorithm for solving the (approximate) shortest vector problem is the LLL lattice basis reduction algorithm\cite{lenstra1982factoring}, attributed to Arjen Lenstra, Hendrik Lenstra, and László Lovász. The reduction algorithm transforms an input basis into an LLL-reduced form parameterized by a real number $\frac{1}{4} < \delta \leq 1$, where the first base vector of the reduced basis is an approximation of the shortest vector. Details of the actual algorithm for obtaining a reduced basis will be discussed in \ref{subsec:lllreduce}. Meanwhile, it is helpful to state the definition of the reduced basis and discuss its relationship to the shortest vector.

\begin{definition}
    A basis $B$ is $\delta$-LLL reduced if two conditions are satisfied
    \begin{enumerate}
    \item For all $j > i$, $\vert\mu_{j, i}\vert \leq \frac{1}{2}$
    \item For all $1 \leq i \leq n-1$, $\delta\Vert \pi_i(\mathbf{b}_i)\Vert^2 \leq \Vert\pi_i(\mathbf{b}_{i+1})\Vert^2$
\end{enumerate}
\end{definition}

The first condition will be discussed in details in \ref{subsec:nearestplane}. For now, we focus on the second condition, which gives us a description of how a reduced basis can be used to approximate the shortest vector.

\begin{theorem}
    If $B$ is $\delta$-LLL reduced basis, then
    $$
    \Vert \mathbf{b}_1 \Vert \leq \alpha^\frac{n-1}{2} \lambda
    $$
    where $\alpha = \frac{1}{\delta - \frac{1}{4}}$
\end{theorem}

\begin{proof}
    First observe the RHS of the condition:
    $$
    \begin{aligned}
    \Vert \pi_i(\mathbf{b}_{i+1})\Vert^2 &= \Vert \sum_{j\geq i}\mu_{i+1, j}\mathbf{b}_j^\ast\Vert^2 \\
    &= \Vert \mu_{i+1, i}\mathbf{b}_i^\ast + \sum_{j\geq i+1}\mu_{i+1, j}\mathbf{b}_j^\ast\Vert^2 \\
    &= \Vert \mu_{i+1, i}\mathbf{b}_i^\ast + \pi_{i+1}(\mathbf{b}_{i+1}) \Vert^2 \\
    &= \Vert \mu_{i+1, i}\mathbf{b}_i^\ast + \mathbf{b}_{i+1}^\ast \Vert^2 \\
    &= \Vert \mu_{i+1, i}\mathbf{b}_i^\ast \Vert^2 + \Vert \mathbf{b}_{i+1}^\ast \Vert^2 \\
    \end{aligned}
    $$

    Substituting the equation back into the condition:

    $$
    \delta\Vert \pi_i(\mathbf{b}_i)\Vert^2 \leq \Vert \mu_{i+1, i}\mathbf{b}_i^\ast \Vert^2 + \Vert \mathbf{b}_{i+1}^\ast \Vert^2
    $$

    Which transforms into:

    $$
    \Vert \mathbf{b}_i^\ast \Vert^2 \leq \frac{1}{(\delta - \mu_{i+1, i}^2)} \Vert \mathbf{b}_{i+1}^\ast \Vert^2
    $$

    By the first clause of the reduced basis we know $\mu_{i+1, i}^2 \leq \frac{1}{4}$, which means that $\frac{1}{\delta - \mu_{i+1, i}^2} \leq \frac{1}{\delta - \frac{1}{4}}$. Denote $\alpha = \frac{1}{\delta - \frac{1}{4}}$, then $\alpha > \frac{4}{3}$, and we have the following inequality:

    $$
    \Vert \mathbf{b}_i^\ast \Vert^2 \leq \alpha \Vert \mathbf{b}_{i+1}^\ast \Vert^2
    $$

    Note that because $\mathbf{b}_1 = \mathbf{b}_1^\ast$, we can recusively evaluate the inequality above can obtain the following closed inequality:

    $$
    \Vert \mathbf{b}_1 \Vert^2 \leq \alpha^{i-1} \Vert \mathbf{b}_{i}^\ast \Vert^2 \leq \alpha^{n-1} \Vert \mathbf{b}_{i}^\ast \Vert^2
    $$

    The inequality above states that $\mathbf{b}_1$ is not longer than $\alpha^{n-1} \Vert \mathbf{b}_{i}^\ast \Vert$ for all $i$, so it must be not longer than the minimum among $\alpha^{n-1} \Vert \mathbf{b}_{i}^\ast \Vert$:

    $$
    \Vert \mathbf{b}_1 \Vert^2 \leq \min_{1 \leq i \leq n}\alpha^{n-1} \Vert \mathbf{b}_{i}^\ast \Vert^2 = \alpha^{n-1} \min_{1 \leq i \leq n}\Vert \mathbf{b}_{i}^\ast \Vert^2
    $$

    From the previou section we've derived that $\lambda \geq \min_{1 \leq i \leq n} \Vert \mathbf{b}_i^\ast \Vert$, which we can plug into the inequality above:

    $$
    \Vert \mathbf{b}_1 \Vert \leq \alpha^\frac{n-1}{2} \lambda
    $$
\end{proof}


In other words, the first base vector of a LLL-reduced basis is an approximation of the true shortest vector within an exponential factor.


\subsection{Fundamental regions}
A fundamental region $S$ is a subset of the (real) linear span of the basis such that it tiles the linear span of the basis and each tile contains exactly one lattice point. If we have a fundamental region $S$ defined, then each point in the linear span of the basis can be uniquely decomposed into the sum of a lattice point and a point in the fundamental region:

$$
\operatorname{span}(B) = \{S + B\mathbf{x} \mid \mathbf{x} \in \mathbb{Z}^n\}
$$

A few notable examples include the fundamental parallelpiped 

$$
\mathcal{P}(B) = \{B\mathbf{x} \mid \mathbf{x} \in [0, 1)^n\}
$$

and the centered fundamental parallelpiped

$$
\mathcal{C}(B) = \{B\mathbf{x} \mid \mathbf{x} \in [-\frac{1}{2}, \frac{1}{2})^n\}
$$

Computing the decomposition using the (centered) fundamental parallelpiped is easy. First compute $B^{-1}\mathbf{t}$ (over $\mathbb{R}$), then perform some kind of rounding (flooring or nearest integer) depending on whether the fundamental parallelpiped is centered or or not. $B\lfloor B^{-1}\mathbf{T} \rceil$ is the lattice point whose corresponding fundamental region contains the target. As we will discuss in section 3, when the basis is short and orthogonal, this rounding algorithm indeed provides a good approximate solution to the closest vector problem. However, when the basis is long and skewed, these fundamental regions become terrible approximation.

A better approximation for the closest vector problem can be found using a fundamental region defined by the centered paralellpiped spanned by the orthogonalized basis:

$$
\mathcal{C}(B^\ast) = \{B^\ast\mathbf{x} \mid \mathbf{x} \in [-\frac{1}{2}, \frac{1}{2})^n\}
$$

Because $B^\ast$ is an orthogonal basis, it's easy to see that the sphere centered at some lattice point $\mathbf{v} \in \mathcal{L}$ and whose radius is $\frac{1}{2}\min \Vert \mathbf{b}_i^\ast\Vert$ is entirely contained in the (shifted) fundamental region $\text{sphere} \subset \{\mathcal{C}(B^\ast) + \mathbf{v}\}$. If a target point $\mathbf{t}$ falls in such a sphere, then the corresponding lattice point is the closest lattice point to that target point.

\subsection{Babai's nearest plane algorithm}\label{subsec:nearestplane}
Babai's nearest plane algorithm, attributed to László Babai, is a recursive algorithm that can approximate the closest vector under a given basis to a target vector. More specifically, it returns a vector point $\mathbf{v}$ such that, if target vector is projected onto the orthogonalized basis, the projection is contained in $\mathbf{v} + \mathcal{C}(B^\ast)$. If the target vector is in the linear span of the basis, then the target vector itself is contained in $\mathbf{v} + \mathcal{C}(B^\ast)$.

\begin{algorithm}
\caption{NearestPlane}
\begin{algorithmic}[1]
    \If{$B$ is empty}
        \State return $\mathbf{0}$
    \EndIf 
    \State $B^\ast \leftarrow \text{GramSchmidt}(B)$
    \State $c \leftarrow \lfloor \frac{\langle\mathbf{t}, \mathbf{b}_n^\ast\rangle}{\langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle} \rceil$, where $\mathbf{b}_n^\ast$ is the last base vector in $B^\ast$
    \State return $c\mathbf{b}_n + \text{NearestPlane}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{n-1}], \mathbf{t} - c\mathbf{b}_n)$
\end{algorithmic}
\end{algorithm}


\begin{theorem}
    Given basis $B$ and target $\mathbf{t}$, denote the output of $\operatorname{NearestPlane}$ by $\mathbf{v} \leftarrow \operatorname{NearestPlane}(B, \mathbf{t})$, then for all $1 \leq i \leq n$:

    $$
    \frac{
        \langle
            \mathbf{t} - \mathbf{v}, \mathbf{b}_i^\ast
        \rangle
    }{
        \langle
            \mathbf{b}_i^\ast, \mathbf{b}_i^\ast
        \rangle
    } 
    \in [-\frac{1}{2}, \frac{1}{2})
        $$
    \end{theorem}

Intuitively, the inequality above states that the deviation of $\mathbf{t}$ from $\mathbf{v}$ is between $-\frac{1}{2}\mathbf{b}_i^\ast$ and $\frac{1}{2}\mathbf{b}_i^\ast$ in any of the chosen direction $\mathbf{b}_i^\ast$, which means that $\mathbf{t} - \mathbf{v}$ is indeed contained in the orthogonalized fundamental parallelpiped.

\begin{proof}
    We will prove by induction. The base case correpsonds to $B$ being an empty basis, and so this statement is vacuously true.
    
    In the inductive case, we denote the output of $\text{NearestPlane}(B', \mathbf{t} - c\mathbf{b}_n)$ by $\mathbf{v}^\prime$. Assuming that the algorithm produces the desired result for the sublattice $\mathcal{L}(B^\prime)$:

    $$
    \forall 1 \leq i \leq (n-1), 
    \frac{
        \langle
            (\mathbf{t} - c\mathbf{b}_n) - \mathbf{v}^\prime, 
            \mathbf{b}_i^\ast
        \rangle
    }{
        \langle
            \mathbf{b}_i^\ast, \mathbf{b}_i^\ast
        \rangle
    } \in [-\frac{1}{2}, \frac{1}{2})
    $$

    However, notice in step 5 of the algorithm $c\mathbf{b}_n + \mathbf{v}^\prime$ is the output of the current iteration of the algorithm: $\mathbf{v} = c\mathbf{b}_n + \mathbf{v}^\prime$, therefore:

    $$
    \begin{aligned}
    (\mathbf{t} - c\mathbf{b}_n) - \mathbf{v}^\prime 
    &= \mathbf{t} - (c\mathbf{b}_n + \mathbf{v}^\prime) \\
    &= \mathbf{t} - \mathbf{v}
    \end{aligned}
    $$

    which means that

    $$
    \forall 1 \leq i \leq (n-1), 
    \frac{
        \langle
            \mathbf{t} - \mathbf{v}, 
            \mathbf{b}_i^\ast
        \rangle
    }{
        \langle
            \mathbf{b}_i^\ast, \mathbf{b}_i^\ast
        \rangle
    } \in [-\frac{1}{2}, \frac{1}{2})
    $$

    It remains show that this relationship also holds for $i = n$.

    To prove that the relationship holds for $i = n$, first observe how $c$ is computed:

    $$
    c \leftarrow \lfloor \frac{\langle\mathbf{t}, \mathbf{b}_n^\ast\rangle}{\langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle} \rceil
    $$

    which is equivalent to saying that

    $$
    \frac{
        \langle\mathbf{t}, \mathbf{b}_n^\ast\rangle
    }{
        \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    }
    - c \in [-\frac{1}{2}, \frac{1}{2})
    $$

    Also recall the Gram-Schmidt orthogonalization process:

    $$
    \mathbf{b}_n^\ast +\sum_{i<n}\mu_{n, i}\mathbf{b}_i^\ast = \mathbf{b}_n
    $$

    Therefore

    $$
    \begin{aligned}
    \langle\mathbf{b}_n, \mathbf{b}_n^\ast\rangle
    &= \langle 
        \mathbf{b}_n^\ast +\sum_{i<n}\mu_{n, i}\mathbf{b}_i^\ast, \mathbf{b}_n^\ast
    \rangle \\
    &= \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    \end{aligned}
    $$

    All non $\mathbf{b}_n^\ast$ terms can be cleared because they are orthogonal to $\mathbf{b}_n^\ast$ and their inner product is 0. This equality means that:

    $$
    \frac{
        \langle\mathbf{b}_n, \mathbf{b}_n^\ast\rangle
    }{
        \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    } = 1
    $$

    Because $\mathbf{v}^\prime$ is a sub-lattice point, it is a linear combination of $\{\mathbf{b}_j\}_{j<n}$, which is orthogonal to $\mathbf{b}_n^\ast$, so $\mathbf{v}^\prime$ is also orthogonal to $\mathbf{b}_n^\ast$.

    Finally we can put everything together:

    $$
    \begin{aligned}
    \frac{
        \langle\mathbf{t}, \mathbf{b}_n^\ast\rangle
    }{
        \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    }
    - c 
    &= \frac{
        \langle\mathbf{t}, \mathbf{b}_n^\ast\rangle
    }{
        \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    }
    - c \frac{
        \langle\mathbf{b}_n, \mathbf{b}_n^\ast\rangle
    }{
        \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    } \\
    &= \frac{
        \langle\mathbf{t} - c\mathbf{b}_n, \mathbf{b}_n^\ast\rangle
    }{
        \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    } \\
    &= \frac{
        \langle\mathbf{t} - c\mathbf{b}_n - \mathbf{v}^\prime, \mathbf{b}_n^\ast\rangle
    }{
        \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    } \\
    &= \frac{
        \langle\mathbf{t} - \mathbf{v}, \mathbf{b}_n^\ast\rangle
    }{
        \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
    } \in [-\frac{1}{2}, \frac{1}{2})
    \end{aligned}
    $$

    Hence we've proved the relationship for $i = n$.
\end{proof}

Babai's nearest plane algorithm is an essential component to the LLL lattice basis reduction algorithm. Specifically, the nearest plane algorithm is used to reduce the size of the basis vector so the first condition of the reduced basis (shown below) can be satisfied:

$$
\forall j<i, \vert\mu_{i, j}\vert \leq \frac{1}{2}
$$

The size reduction algorithm, which we will denote by $\operatorname{SizeReduce}$, takes a basis $B$ and returns a size-reduced basis $B^\prime$ such that the condition above is true.

\begin{algorithm}
\caption{SizeReduce}
\begin{algorithmic}[1]
    \For{$i \in \{2, 2, \ldots, n\}$}
        \State $\mathbf{v} \in \mathcal{L}([\mathbf{b}_1, \ldots, \mathbf{b}_{i-1}]) \leftarrow \operatorname{NearestPlane}([\mathbf{b}_1, \ldots, \mathbf{b}_{i-1}], \mathbf{b}_i - \mathbf{b}_i^\ast)$
        \State $\mathbf{b}_i \leftarrow \mathbf{b}_i - \mathbf{v}$
    \EndFor
\end{algorithmic}
\end{algorithm}

Recall the result of the nearest plane algorithm we know that:

$$
\forall j < i,
\frac{
    \langle
        \mathbf{b}_i - \mathbf{b}_i^\ast - \mathbf{v}, \mathbf{b}_j^\ast
    \rangle
}{
    \langle 
        \mathbf{b}_j^\ast, \mathbf{b}_j^\ast
    \rangle
} \in [-\frac{1}{2}, \frac{1}{2})
$$

Notice in the equation above, we have $\mathbf{b}_i^\ast \perp \mathbf{b}_j^\ast$ because $j < i$. We also have $\mathbf{b}_i - \mathbf{v}$ being the new value for $\mathbf{v}_i$ after the substitution. This means that after the substitution:

$$
\forall j < i,
\frac{
    \langle
        \mathbf{b}_i, \mathbf{b}_j^\ast
    \rangle
}{
    \langle
        \mathbf{b}_j^\ast, \mathbf{b}_j^\ast
    \rangle
} \in [-\frac{1}{2}, \frac{1}{2})
$$

The LHS of the equation above is exactly $\mu_{i,j}$. Thus we have satisfied the first condition of $\delta$-LLL reduced basis. In addition, because $\mathbf{v} \in \mathcal{L}([\mathbf{b}_1, \ldots, \mathbf{b}_{i-1}])$, the substitution $\mathbf{b}_i \leftarrow \mathbf{b}_i - \mathbf{v}$ is equivalent to adding onto the substituted basis a linear combination of other base vectors, which does not change the lattice.

%%%%% SECTION: LLL basis reduction algorithm %%%%%
\subsection{The LLL basis reduction algorithm}\label{subsec:lllreduce}
Applying the $\operatorname{SizeReduce}$ algorithm to a basis transforms it to satisfy the first condition of being $\delta$-LLL reduced. However, after the transformation, the second condition might not be satisfied everywhere, and we need to apply additional transformation to satisfy the second condition:

$$
\delta \Vert \pi_i(\mathbf{b}_i) \Vert^2 \leq \Vert \pi_i(\mathbf{b}_{i+1})\Vert^2
$$

It turns out that such transformation is rather simple: if there is some $i$ such that the condition above does not hold, then swapping $\mathbf{b}_i$ and $\mathbf{b}_{i+1}$ will make the pair satisfy the condition. To see that it works, denote the swapped basis vectors by $\mathbf{b}_i^\prime = \mathbf{b}_{i+1}$, $\mathbf{b}_{i+1}^\prime = \mathbf{b}_{i}$. First observe that the function $\pi_i: \mathbf{x} \mapsto \sum_{j\geq i}\frac{\langle \mathbf{x}, \mathbf{b}_j^\ast \rangle}{\langle \mathbf{b}_j^\ast, \mathbf{b}_j^\ast \rangle}\mathbf{b}_j^\ast$ is not changed after the swap because it is still projecting $\mathbf{x}$ onto the same set of orthogonal basis, and the set of orthogonal basis is unchanged by the swap.

If the condition does not hold, then $\delta\Vert\pi_i(\mathbf{b}_i)\Vert^2 > \Vert\pi_i(\mathbf{b}_{i+1})\Vert^2$, and we have

$$
\begin{aligned}
\delta \Vert\pi_i(\mathbf{b}_i^\prime)\Vert^2
&= \delta \Vert\pi_i(\mathbf{b}_{i+1})\Vert^2 \\
&< \delta \cdot \delta\Vert\pi_i(\mathbf{b}_i)\Vert^2 \\
&\leq \Vert\pi_i(\mathbf{b}_i)\Vert^2 \\
&= \Vert\pi_i(\mathbf{b}_{i+1}^\prime)\Vert^2
\end{aligned}
$$

We know that swapping columns preserves the lattice, so we can define a second algorithm $\operatorname{ColumnSwap}$ that takes a basis $B$ and transforms it into a second basis of the same lattice that satisfies the second condition of $\delta$-LLL reduced basis:

\begin{algorithm}
\caption{ColumnSwap}
\begin{algorithmic}[1]
    \For{$i \in \{1, 2, \ldots, n-1\}$}
        \If{$\delta\Vert\pi_i(\mathbf{b}_i)\Vert^2 > \Vert \pi_i(\mathbf{b}_{i+1}) \Vert^2$}
            \State $\mathbf{b}_i \leftarrow \mathbf{b}_{i+1}$
            \State $\mathbf{b}_{i+1} \leftarrow \mathbf{b}_{i}$
        \EndIf
    \EndFor
\end{algorithmic}
\end{algorithm}

It's easy to see that $\operatorname{ColumnSwap}$ always terminates in $n$ iterations, and upon termination, the transformed basis satisfies the second condition of being $\delta$-LLL reduced. Unforutnately, now the first condition might not hold everywhere, so we need to apply $\operatorname{SizeReduce}$ again.

Indeed, the LLL basis reduction algorithm repeatedly alternates between applying the two steps $\operatorname{SizeReduce}$ and $\operatorname{ColumnSwap}$ until the basis becomes $\delta$-LLL reduced. It's trivially true that if the algorithm terminates, the output is guaranteed to satisfy both conditions of being $\delta$-LLL reduced. It remains to show that, at least for $\delta < 1$, this algorithm terminates in polynomial time.

\begin{algorithm}
\caption{LLLReduce}
\begin{algorithmic}[1]
    \While{$B$ is not $\delta$-LLL reduced}
        \State $B \leftarrow \operatorname{SizeReduce}(B)$
        \State $B \leftarrow \operatorname{ColumnSwap}(B)$
    \EndWhile
\end{algorithmic}
\end{algorithm}

\begin{theorem}
    For $\delta < 1$, reducing a basis to $\delta$-LLL reduced form takes polynomial time
\end{theorem}
\begin{proof}
    To prove that $\operatorname{LLLReduce}$ will terminate in polynomial time, we define a positive integer quantity associated with a basis and show that each iteration of $\operatorname{SizeReduce}$ and $\operatorname{ColumnSwap}$ reduce this quantity by $\delta$.

    Recall that although determinant is not defined for non-square matrix, it is defined for (sub)lattice generated by sub-basis $B_k = [\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_k] \in \mathbb{Z}^{n \times k}$ where $1 \leq k \leq n$:

    $$
    \det(\mathcal{L}(B_k)) = \prod_{i=1}^k \Vert \mathbf{b}_i^\ast \Vert = \sqrt{B_k^\intercal B_k}
    $$

    From the definition above we can see that the square of the determinant of a lattice generated by integer basis is an integer. 

    We define the "potential" of a full-rank basis $B = [\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_n]$ by the product of determinants of sub-lattices generated by sub-basis $B_1, B_2, \ldots, B_n$:

    $$
    \mathcal{D} = \prod_{k=1}^n \det(\mathcal{L}(B_k))^2
    $$

    $\mathcal{D}$, being a product of integers, is itself an integer.

    First observe that in $\operatorname{SizeReduce}$, the basis vector is changed by subtracting a linear combination of basis vectors before the changed basis vector. This means that after $\operatorname{SizeReduce}$, each of $B_k$ for $1\leq k \leq n$ still generates the same lattice, and the determinant of that lattice remains unchanged. In other words, $\operatorname{SizeReduce}$ does not change the value of $\mathcal{D}$.

    Second, for $k < i$, swapping column $\mathbf{b}_i$ with $\mathbf{b}_{i+1}$ does not affect the lattice generated by the partial basis $B_k$ because $B_k = \{\mathbf{b}_1, \ldots, \mathbf{b}_{i-1}\}$ does not contain the swapped columns anyways. On the other hand, for $k > i$, swapping column $\mathbf{b}_i$ with $\mathbf{b}_{i+1}$ also does not affect the lattice generated by the partial basis $B_k$ because it contains both of the swapped column, and swapping column preserves the lattice.

    Therefore the only change to $\mathcal{D}$ when swapping $\mathbf{b}_i$ with $\mathbf{b}_{i+1}$ comes from the factor $\det(\mathcal{L}(B_i))$. Denote the potential of the basis $B$ after the swap by $\mathcal{D}^\prime$ then:

    $$
    \frac{\mathcal{D}}{\mathcal{D}^\prime} = \frac{
        \det(\mathcal{L}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{i-1}, \mathbf{b}_{i}]))^2
    }{
        \det(\mathcal{L}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{i-1}, \mathbf{b}_{i+1}]))^2
    }
    $$

    Recall that the determinant of a lattice is the product of the orthogonalized basis vectors. The first $i-1$ terms are identical between the two basis so they all cancel out. The $i$-th term on the numerator is exactly $\mathbf{b}_i^\ast$, while the $i$-th term on the denominator is as follows:

    $$
    \begin{aligned}
    \text{last orthogonalized vector in the denominator} 
    &= \mathbf{b}_{i+1} - \sum_{j < i} \mu_{i+1, j}\mathbf{b}_j^\ast \\
    &= \mathbf{b}_{i+1} - (\sum_{1 \leq j \leq n} \mu_{i+1, j}\mathbf{b}_j^\ast  
        - \sum_{j \geq i} \mu_{i+1, j}\mathbf{b}_j^\ast) \\
    &= \mathbf{b}_{i+1} - (\mathbf{b}_{i+1}  
        - \sum_{j \geq i} \mu_{i+1, j}\mathbf{b}_j^\ast) \\
    &= \sum_{j \geq i} \mu_{i+1, j}\mathbf{b}_j^\ast \\
    &= \pi_i(\mathbf{b}_{i+1})
    \end{aligned}
    $$

    Therefore we have:

    $$
    \frac{\mathcal{D}}{\mathcal{D}^\prime} = \frac{
        \det(\mathcal{L}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{i-1}, \mathbf{b}_{i}]))^2
    }{
        \det(\mathcal{L}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{i-1}, \mathbf{b}_{i+1}]))^2
    } = \frac{\Vert\mathbf{b}_i^\ast\Vert^2}{\Vert\pi_i(\mathbf{b}_{i+1})\Vert^2}
    = \frac{\Vert\pi_i(\mathbf{b}_{i})\Vert^2}{\Vert\pi_i(\mathbf{b}_{i+1})\Vert^2}
    $$

    Because we only swap when $\delta \Vert \pi_i(\mathbf{b}_i) \Vert^2 > \Vert \pi_i(\mathbf{b}_{i+1}) \Vert^2$, the quotient above satisfies:

    $$
    \frac{\mathcal{D}}{\mathcal{D}^\prime} 
    = \frac{\Vert\pi_i(\mathbf{b}_{i})\Vert^2}{\Vert\pi_i(\mathbf{b}_{i+1})\Vert^2}
    > \frac{1}{\delta}
    $$

    Which implies $\mathcal{D}^\prime < \delta \mathcal{D}$.

    Notice that in the relationship above, the second condition of being $\delta$-LLL reduced is violated if and only if $\mathcal{D}^\prime < \delta\mathcal{D}$. This means that when $\mathcal{D}^\prime \geq \delta\mathcal{D}$, the second condition will hold. Indeed, when the potential converges, the algorithm terminates, and since each iteration reduces the potential by $\delta$, we can deduce that the algorithm will terminate in $O(\log_{\frac{1}{\delta}}\mathcal{D})$ time.
\end{proof}
