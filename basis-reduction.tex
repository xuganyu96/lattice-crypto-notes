\section{Hard lattice problems and best known solutions}
We begin the discussion of hard lattice problems by defining two such problems.

\begin{definition}
    Given a lattice $\mathcal{L}(B)$ spanned by basis $B$ and a norm $\Vert \cdot \Vert \rightarrow \mathbb{R}$, the \textbf{shortest vector problem} asks to find the shortest non-zero vector
\end{definition}

The norm of the shortest non-zero vector is called the \textbf{minimum distance} and is denoted by $\lambda(\mathcal{L})$. Where the lattice is unambiguous we simply denote the minimum distance by $\lambda$.

\begin{definition}
    Given a lattice $\mathcal{L}(B)$, a norm, and some target vector $\mathbf{t}$ in the same vector space as the lattice, the \textbf{closest vector problem} asks to find a lattice point $\mathbf{v} \in \mathcal{L}$ that minimizes $\Vert \mathbf{t} - \mathbf{v}\Vert$
\end{definition}

There are two main parameters that affect the difficulty of SVP and CVP. The first is the number of dimensions $n$: the higher the number of dimension, the harder it is to find the shortest vector and/or the closest vector. The second is the orthogonality and/or the length of the basis. Intuitively, orthogonality and length are inversely related because the determinant of the lattice is invariant with respect to the choice of basis: higher orthogonality automatically implies shorter lengths. The more skewed the choice of basis, the more difficult it is to solve SVP/CVP.

In general, it is difficult to find the exact shortest vector or the closest vector. Instead, we introduce an "approximation factor" $\gamma$ and define the approximate SVP:

\begin{definition}
    Given a lattice $\mathcal{L}(B)$ spanned by basis $B$ and a norm $\Vert \cdot \Vert \rightarrow \mathbb{R}$, the $\gamma$-\textbf{shortest vector problem} asks to find a vector $\mathbf{v} \in \mathcal{L}$ such that $\Vert \mathbf{v} \Vert \leq \gamma \lambda$
\end{definition}

The definition of CVP is similar and omitted.

\subsection{Minimum distance and orthogonalized basis}
The minimum distnace of a lattice is bounded below by the shortest orthogonalized basis:

\begin{theorem}
    Given lattice $\mathcal{L}(B)$ with basis $B = [\mathbf{b}_1, \ldots, \mathbf{b}_n]$, denote the Gram-Schmidt orthognoalized basis by $B^\ast = [\mathbf{b}_1^\ast, \ldots, \mathbf{b}_n^\ast]$, then

    $$
    \lambda \geq \min_{1 \leq i \leq n} \Vert \mathbf{b}_i^\ast \Vert
    $$
\end{theorem}

To prove this lower bound, we first prove a recursive relationship. The closed relationship can be easily derived by applying the recursive relationship $n$ times.

$$
\lambda \geq \min(
    \lambda([\mathbf{b}_i, \ldots, \mathbf{b}_{n-1}]),
    \Vert\mathbf{b}_n^\ast\Vert
)
$$

For convenience, we denote the orthogonalization coefficient by:

$$
\mu_{i, j} = \frac{\langle \mathbf{b}_i, \mathbf{b}_j^*\rangle}{\langle \mathbf{b}_j^*, \mathbf{b}_j^*\rangle}
$$

Also, we define a function $\pi_i$ that projects a vector from $\mathbb{R}^n$ onto the orthogonal basis formed by $\mathbf{b}_i^\ast, \mathbf{b}_{i+1}^\ast, \ldots, \mathbf{b}_n^\ast$:

$$
\pi_i(\mathbf{x}) = \sum_{j\geq i}\frac{\langle \mathbf{x}, \mathbf{b}_j^\ast\rangle}{\langle \mathbf{b}_j^\ast, \mathbf{b}_j^\ast \rangle}\mathbf{b}_j^\ast
$$

Observe that for $i = 1$, $\pi_i$ is the identity function, because the orthogonalized basis still span the same vector space as the original basis. Also, $\pi_i(\mathbf{b}_i) = \mathbf{b}_i^\ast$:

$$
\begin{aligned}
\pi_i(\mathbf{b}_i) &= \sum_{j\geq i}\frac{\langle \mathbf{b}_i, \mathbf{b}_j^\ast\rangle}{\langle \mathbf{b}_j^\ast, \mathbf{b}_j^\ast \rangle}\mathbf{b}_j^\ast \\
&= \sum_{1 \leq j \leq n}\frac{\langle \mathbf{b}_i, \mathbf{b}_j^\ast\rangle}{\langle \mathbf{b}_j^\ast, \mathbf{b}_j^\ast \rangle}\mathbf{b}_j^\ast  - \sum_{j < i}\frac{\langle \mathbf{b}_i, \mathbf{b}_j^\ast\rangle}{\langle \mathbf{b}_j^\ast, \mathbf{b}_j^\ast \rangle}\mathbf{b}_j^\ast \\
&= \pi_1(\mathbf{b}_i) - \sum_{j < i}\frac{\langle \mathbf{b}_i, \mathbf{b}_j^\ast\rangle}{\langle \mathbf{b}_j^\ast, \mathbf{b}_j^\ast \rangle}\mathbf{b}_j^\ast \\
&= \mathbf{b}_i - \sum_{j < i}\frac{\langle \mathbf{b}_i, \mathbf{b}_j^\ast\rangle}{\langle \mathbf{b}_j^\ast, \mathbf{b}_j^\ast \rangle}\mathbf{b}_j^\ast \\
&= \mathbf{b}_i^\ast
\end{aligned}
$$

To prove the recursive relationship, denote an arbitrary lattice point by $\mathbf{v} = B\mathbf{x}$ for some $\mathbf{x} \in \mathbb{Z}^n$. If the coefficient of the last base vector is not zero, then the lattice point must be at least as long as $\Vert \mathbf{b}_n^\ast \Vert$:

$$
\begin{aligned}
\Vert B\mathbf{x} \Vert^2 &= \Vert \sum_{i=1}^n\mathbf{b}_i x_i \Vert^2 \\
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + \mathbf{b}_nx_n \Vert^2 \\
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + (\mathbf{b}_n^* + \sum_{j<n}\mu_{j, n}\mathbf{b}_j^\ast)x_n \Vert^2 \\
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + (\sum_{j<n}\mu_{j, n}\mathbf{b}_j^\ast) x_n  + \mathbf{b}_n^\ast x_n\Vert^2
\end{aligned}
$$

Observe that by the definition of the orthogonalization process, $\mathbf{b}_n^\ast$ is orthogonal to all other orthogonal basis $\mathbf{b}_1^\ast, \mathbf{b}_2^\ast, \ldots, \mathbf{b}_{n-1}^\ast$, as well as all except the identically indexed original basis $\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{n-1}$. By Pythagoras theorem we can separate the RHS into orthogonal components:

$$
\begin{aligned}
\Vert B\mathbf{x} \Vert^2 
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + (\sum_{j<n}\mu_{j, n}\mathbf{b}_j^\ast) x_n  + \mathbf{b}_n^\ast x_n\Vert^2 \\
&= \Vert \sum_{i=1}^{n-1}\mathbf{b}_ix_i + (\sum_{j<n}\mu_{j, n}\mathbf{b}_j^\ast) x_n \Vert^2 + \Vert \mathbf{b}_n^\ast x_n \Vert^2 \\
&\geq \Vert \mathbf{b}_n^\ast x_n \Vert^2 \\
&\geq \Vert \mathbf{b}_n^\ast \Vert^2
\end{aligned}
$$

On the other hand, if the coefficient for the last base vector is zero, then the lattice point is at least as long as the shortest vector in the sub-lattice with the last base vector removed $\lambda(B) = \lambda([\mathbf{b}_1, \ldots, \mathbf{b}_{n-1}])$. Putting the two cases together gives us the recursive relationship. $\blacksquare$

\subsection{Reduced lattice basis}
At the time of this survey, the best algorithm for solving the (approximate) shortest vector problem is the LLL lattice basis reduction algorithm, attributed to Arjen Lenstra, Hendrik Lenstra, and László Lovász. The reduction algorithm transforms an input basis into an LLL-reduced form \cite{lenstra1982factoring}, where the first base vector of the reduced basis is an approximation of the shortest vector. Details of the actual algorithm for obtaining a reduced basis will be discussed later in this section. Meanwhile, it is helpful to first discuss the properties of the reduced form itself.

\begin{definition}
    A basis $B$ is $\delta$-LLL reduced if two conditions are satisfied
    \begin{enumerate}
    \item For all $j > i$, $\vert\mu_{j, i}\vert \leq \frac{1}{2}$
    \item For all $1 \leq i \leq n-1$, $\delta\Vert \pi_i(\mathbf{b}_i)\Vert^2 \leq \Vert\pi_i(\mathbf{b}_{i+1})\Vert^2$
\end{enumerate}
\end{definition}

The first condition will be discussed in details in the next subsection. For now, we focus on the second condition, which gives us a description of how a reduced basis can be used to approximate the shortest vector. First observe the RHS of the condition:

$$
\begin{aligned}
\Vert \pi_i(\mathbf{b}_{i+1})\Vert^2 &= \Vert \sum_{j\geq i}\mu_{i+1, j}\mathbf{b}_j^\ast\Vert^2 \\
&= \Vert \mu_{i+1, i}\mathbf{b}_i^\ast + \sum_{j\geq i+1}\mu_{i+1, j}\mathbf{b}_j^\ast\Vert^2 \\
&= \Vert \mu_{i+1, i}\mathbf{b}_i^\ast + \pi_{i+1}(\mathbf{b}_{i+1}) \Vert^2 \\
&= \Vert \mu_{i+1, i}\mathbf{b}_i^\ast + \mathbf{b}_{i+1}^\ast \Vert^2 \\
&= \Vert \mu_{i+1, i}\mathbf{b}_i^\ast \Vert^2 + \Vert \mathbf{b}_{i+1}^\ast \Vert^2 \\
\end{aligned}
$$

Substituting the equation back into the condition:

$$
\delta\Vert \pi_i(\mathbf{b}_i)\Vert^2 \leq \Vert \mu_{i+1, i}\mathbf{b}_i^\ast \Vert^2 + \Vert \mathbf{b}_{i+1}^\ast \Vert^2
$$

Which transforms into:

$$
\Vert \mathbf{b}_i^\ast \Vert^2 \leq \frac{1}{(\delta - \mu_{i+1, i}^2)} \Vert \mathbf{b}_{i+1}^\ast \Vert^2
$$

By the first clause of the reduced basis we know $\mu_{i+1, i}^2 \leq \frac{1}{4}$, which means that $\frac{1}{\delta - \mu_{i+1, i}^2} \leq \frac{1}{\delta - \frac{1}{4}}$. Denote $\alpha = \frac{1}{\delta - \frac{1}{4}}$, then $\alpha > \frac{4}{3}$, and we have the following inequality:

$$
\Vert \mathbf{b}_i^\ast \Vert^2 \leq \alpha \Vert \mathbf{b}_{i+1}^\ast \Vert^2
$$

Note that because $\mathbf{b}_1 = \mathbf{b}_1^\ast$, we can recusively evaluate the inequality above can obtain the following closed inequality:

$$
\Vert \mathbf{b}_1 \Vert^2 \leq \alpha^{i-1} \Vert \mathbf{b}_{i}^\ast \Vert^2 \leq \alpha^{n-1} \Vert \mathbf{b}_{i}^\ast \Vert^2
$$

The inequality above states that $\mathbf{b}_1$ is not longer than $\alpha^{n-1} \Vert \mathbf{b}_{i}^\ast \Vert$ for all $i$, so it must be not longer than the minimum among $\alpha^{n-1} \Vert \mathbf{b}_{i}^\ast \Vert$:

$$
\Vert \mathbf{b}_1 \Vert^2 \leq \min_{1 \leq i \leq n}\alpha^{n-1} \Vert \mathbf{b}_{i}^\ast \Vert^2 = \alpha^{n-1} \min_{1 \leq i \leq n}\Vert \mathbf{b}_{i}^\ast \Vert^2
$$

From the previou section we've derived that $\lambda \geq \min_{1 \leq i \leq n} \Vert \mathbf{b}_i^\ast \Vert$, which we can plug into the inequality above:

$$
\Vert \mathbf{b}_1 \Vert \leq \alpha^\frac{n-1}{2} \lambda
$$

This in equality bounds the length of the first base vector of the reduced basis by some multiples of the minimum distance, where the multiple is exponential with respect to the number of dimensions of the lattice.

In other words, the first base vector of a reduced basis is an approximation of the shortest vector within a factor of $\gamma \in O(\alpha^n)$. With specific choices of "bad" basis and sufficiently high dimension $n$, the basis reduction algorithm will not be able to provide meaningfully tight approximation of the shortest vector, making the shortest vector problem suitably hard for cryptographic applications.


\subsection{Fundamental regions}
A fundamental region $S$ is a subset of the (real) linear span of the basis such that it tiles the linear span of the basis and each tile contains exactly one lattice point. If we have a fundamental region $S$ defined, then each point in the linear span of the basis can be uniquely decomposed into the sum of a lattice point and a point in the fundamental region:

$$
\mathcal{L}(B) = \{S + B\mathbf{x} \mid \mathbf{x} \in \mathbb{Z}^n\}
$$

A few notable examples include the fundamental parallelpiped 

$$
\mathcal{P}(B) = \{B\mathbf{x} \mid \mathbf{x} \in [0, 1)^n\}
$$

and the centered fundamental parallelpiped

$$
\mathcal{C}(B) = \{B\mathbf{x} \mid \mathbf{x} \in [-\frac{1}{2}, \frac{1}{2})^n\}
$$

Computing the decomposition using the (centered) fundamental parallelpiped is easy. First compute $B^{-1}\mathbf{t}$ (over $\mathbb{R}$), then perform some kind of rounding (flooring or nearest integer) depending on whether the fundamental parallelpiped is centered or or not. $B\lfloor B^{-1}\mathbf{T} \rceil$ is the lattice point whose corresponding fundamental region contains the target. This is Babai's rounding algorithm. As we will see in later section, this algorithm works well if $B$ is short and orthogonal, but falls apart badly if $B$ is long and skewed.

The Voronoi region is defined by the set of points in the linear span that are closer to $\mathbf{0}$ than to any other lattice points. There is some additional details that need to be specified to ensure that the Voronoi region properly closes and forms a partition of $\text{span}(B)$, which we will not discuss in details here. If we have an algorithm that can efficiently decompose $\mathbf{t} \in \text{span}(B)$ using the Voronoi region, then we automatically have a way to solve the closest vector problem. Unfortunately, no such algorithm is known.

Of particular interest is the (centered) orthogonalized fundamental parallelpiped, which is defined using the orthogonalized basis $B^\ast = \text{Gram-Schmidt}(B)$:

$$
\mathcal{C}(B^\ast) = \{B^\ast\mathbf{x} \mid \mathbf{x} \in [-\frac{1}{2}, \frac{1}{2})\}
$$

Because $B^\ast$ is an orthogonal basis, it's easy to see that the sphere centered at some lattice point $\mathbf{v} \in \mathcal{L}$ and whose radius is $\frac{1}{2}\min \Vert \mathbf{b}_i^\ast\Vert$ is entirely contained in the (shifted) fundamental region $\text{sphere} \subset \{\mathcal{C}(B^\ast) + \mathbf{v}\}$.

\subsection{Babai's nearest plane algorithm}
Babai's nearest plane algorithm, attributed to László Babai, is a recursive algorithm that can approximate the closest vector under a given basis to a target vector. More specifically, it returns a vector point $\mathbf{v}$ such that, if target vector is projected onto the orthogonalized basis, the projection is contained in $\mathbf{v} + \mathcal{C}(B^\ast)$. If the target vector is in the linear span of the basis, then the target vector itself is contained in $\mathbf{v} + \mathcal{C}(B^\ast)$.

\begin{algorithm}
\caption{NearestPlane}
\begin{algorithmic}[1]
    \If{$B$ is empty}
        \State return $\mathbf{0}$
    \EndIf 
    \State $B^\ast \leftarrow \text{GramSchmidt}(B)$
    \State $c \leftarrow \lfloor \frac{\langle\mathbf{t}, \mathbf{b}_n^\ast\rangle}{\langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle} \rceil$, where $\mathbf{b}_n^\ast$ is the last base vector in $B^\ast$
    \State return $c\mathbf{b}_n + \text{NearestPlane}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{n-1}], \mathbf{t} - c\mathbf{b}_n)$
\end{algorithmic}
\end{algorithm}


\begin{theorem}
    Given basis $B$ and target $\mathbf{t}$, denote the output of $\operatorname{NearestPlane}$ by $\mathbf{v} \leftarrow \operatorname{NearestPlane}(B, \mathbf{t})$, then for all $1 \leq i \leq n$:

    $$
    \frac{
        \langle
            \mathbf{t} - \mathbf{v}, \mathbf{b}_i^\ast
        \rangle
    }{
        \langle
            \mathbf{b}_i^\ast, \mathbf{b}_i^\ast
        \rangle
    } 
    \in [-\frac{1}{2}, \frac{1}{2})
        $$
    \end{theorem}

Intuitively, the inequality above states that the deviation of $\mathbf{t}$ from $\mathbf{v}$ is between $-\frac{1}{2}\mathbf{b}_i^\ast$ and $\frac{1}{2}\mathbf{b}_i^\ast$ in any of the chosen direction $\mathbf{b}_i^\ast$, which means that $\mathbf{t} - \mathbf{v}$ is indeed contained in the orthogonalized fundamental parallelpiped.

We can prove this result inductively. In the base case, if the input set of basis is empty, then this result is trivially correct. In the inductive case, we denote the output of $\text{NearestPlane}(B', \mathbf{t} - c\mathbf{b}_n)$ by $\mathbf{v}^\prime$. Assuming that the algorithm produces the desired result for the sublattice $\mathcal{L}(B^\prime)$:

$$
\forall 1 \leq i \leq (n-1), 
\frac{
    \langle
        (\mathbf{t} - c\mathbf{b}_n) - \mathbf{v}^\prime, 
        \mathbf{b}_i^\ast
    \rangle
}{
    \langle
        \mathbf{b}_i^\ast, \mathbf{b}_i^\ast
    \rangle
} \in [-\frac{1}{2}, \frac{1}{2})
$$

However, notice in step 5 of the algorithm $c\mathbf{b}_n + \mathbf{v}^\prime$ is the output of the current iteration of the algorithm, so we have

$$
\begin{aligned}
(\mathbf{t} - c\mathbf{b}_n) - \mathbf{v}^\prime 
&= \mathbf{t} - (c\mathbf{b}_n + \mathbf{v}^\prime) \\
&= \mathbf{t} - \mathbf{v}
\end{aligned}
$$

which means that

$$
\forall 1 \leq i \leq (n-1), 
\frac{
    \langle
        \mathbf{t} - \mathbf{v}, 
        \mathbf{b}_i^\ast
    \rangle
}{
    \langle
        \mathbf{b}_i^\ast, \mathbf{b}_i^\ast
    \rangle
} \in [-\frac{1}{2}, \frac{1}{2})
$$

So all that remains is to show that this relationship also holds for $i = n$.

To prove that the relationship holds for $i = n$, first observe how $c$ is computed:

$$
c \leftarrow \lfloor \frac{\langle\mathbf{t}, \mathbf{b}_n^\ast\rangle}{\langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle} \rceil
$$

which is equivalent to saying that

$$
\frac{
    \langle\mathbf{t}, \mathbf{b}_n^\ast\rangle
}{
    \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
}
- c \in [-\frac{1}{2}, \frac{1}{2})
$$

Also recall the Gram-Schmidt orthogonalization process:

$$
\mathbf{b}_n^\ast +\sum_{i<n}\mu_{n, i}\mathbf{b}_i^\ast = \mathbf{b}_n
$$

Therefore

$$
\begin{aligned}
\langle\mathbf{b}_n, \mathbf{b}_n^\ast\rangle
&= \langle 
    \mathbf{b}_n^\ast +\sum_{i<n}\mu_{n, i}\mathbf{b}_i^\ast, \mathbf{b}_n^\ast
\rangle \\
&= \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
\end{aligned}
$$

All non $\mathbf{b}_n^\ast$ terms can be cleared because they are orthogonal to $\mathbf{b}_n^\ast$, so their inner product is 0. This equality means that:

$$
\frac{
    \langle\mathbf{b}_n, \mathbf{b}_n^\ast\rangle
}{
    \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
} = 1
$$

Finally we can put everything together:

$$
\begin{aligned}
\frac{
    \langle\mathbf{t}, \mathbf{b}_n^\ast\rangle
}{
    \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
}
- c 
&= \frac{
    \langle\mathbf{t}, \mathbf{b}_n^\ast\rangle
}{
    \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
}
- c \frac{
    \langle\mathbf{b}_n, \mathbf{b}_n^\ast\rangle
}{
    \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
} \\
&= \frac{
    \langle\mathbf{t} - c\mathbf{b}_n, \mathbf{b}_n^\ast\rangle
}{
    \langle\mathbf{b}_n^\ast, \mathbf{b}_n^\ast\rangle
}
\in [-\frac{1}{2}, \frac{1}{2})
\end{aligned}
$$

Hence we've proved the relationship for $i = n$. $\blacksquare$

Babai's nearest plane algorithm is an essential component to the LLL lattice basis reduction algorithm. Specifically, the nearest plane algorithm is used to reduce the size of the basis vector so the first condition of the reduced basis (shown below) can be satisfied:

$$
\forall j<i, \vert\mu_{i, j}\vert \leq \frac{1}{2}
$$

The size reduction algorithm, which we will denote by $\operatorname{SizeReduce}$, takes a basis $B$ and returns a size-reduced basis $B^\prime$ such that the condition above is true. The procedure for $\operatorname{SizeReduce}$ is as follows:

\begin{algorithm}
\caption{SizeReduce}
\begin{algorithmic}[1]
    \For{$i \in \{2, 2, \ldots, n\}$}
        \State $\mathbf{v} \in \mathcal{L}([\mathbf{b}_1, \ldots, \mathbf{b}_{i-1}]) \leftarrow \operatorname{NearestPlane}([\mathbf{b}_1, \ldots, \mathbf{b}_{i-1}], \mathbf{b}_i - \mathbf{b}_i^\ast)$
        \State $\mathbf{b}_i \leftarrow \mathbf{b}_i - \mathbf{v}$
    \EndFor
\end{algorithmic}
\end{algorithm}

Recall the result of the nearest plane algorithm we know that:

$$
\forall j < i,
\frac{
    \langle
        \mathbf{b}_i - \mathbf{b}_i^\ast - \mathbf{v}, \mathbf{b}_j^\ast
    \rangle
}{
    \langle 
        \mathbf{b}_j^\ast, \mathbf{b}_j^\ast
    \rangle
} \in [-\frac{1}{2}, \frac{1}{2})
$$

Notice in the equation above, we have $\mathbf{b}_i^\ast \perp \mathbf{b}_j^\ast$ because $j < i$. We also have $\mathbf{b}_i - \mathbf{v}$ being the new value for $\mathbf{v}_i$ after the substitution. This means that after the substitution:

$$
\forall j < i,
\frac{
    \langle
        \mathbf{b}_i, \mathbf{b}_j^\ast
    \rangle
}{
    \langle
        \mathbf{b}_j^\ast, \mathbf{b}_j^\ast
    \rangle
} \in [-\frac{1}{2}, \frac{1}{2})
$$

The LHS of the equation above is exactly $\mu_{i,j}$. Thus we have satisfied the first condition of $\delta$-LLL reduced basis. In addition, because $\mathbf{v} \in \mathcal{L}([\mathbf{b}_1, \ldots, \mathbf{b}_{i-1}])$, the substitution $\mathbf{b}_i \leftarrow \mathbf{b}_i - \mathbf{v}$ is equivalent to adding onto the substituted basis a linear combination of other basis vectors, which corresponds to a unimodular matrix multiplication and thus does not change the lattice itself before or after the size reduction.

\subsection{The LLL basis reduction algorithm}
Now that we have the $\operatorname{SizeReduce}$ algorithm which takes a basis and transforms it into a size-reduced basis for the same lattice that satisfies the first condition of a $\delta$-LLL reduced basis, it remains somehow transform the basis to satisfy the second condition:

$$
\delta \Vert \pi_i(\mathbf{b}_i) \Vert^2 \leq \Vert \pi_i(\mathbf{b}_{i+1})\Vert^2
$$

It turns out that such transformation is rather simple: if there is some $i$ such that the condition above does not hold, then we can simply swap $\mathbf{b}_i$ and $\mathbf{b}_{i+1}$, and the condition will hold. To see that it works, denote the swapped basis vectors by $\mathbf{b}_i^\prime = \mathbf{b}_{i+1}$, $\mathbf{b}_{i+1}^\prime = \mathbf{b}_{i}$. First observe that the function $\pi_i: \mathbf{x} \mapsto \sum_{j\geq i}\frac{\langle \mathbf{x}, \mathbf{b}_j^\ast \rangle}{\langle \mathbf{b}_j^\ast, \mathbf{b}_j^\ast \rangle}\mathbf{b}_j^\ast$ is not changed after the swap because it is still projecting $\mathbf{x}$ onto the same set of orthogonal basis, and the set of orthogonal basis is unchanged by the swap.

if the condition does not hold, then $\delta\Vert\pi_i(\mathbf{b}_i)\Vert^2 > \Vert\pi_i(\mathbf{b}_{i+1})\Vert^2$, and we have

$$
\begin{aligned}
\delta \Vert\pi_i(\mathbf{b}_i^\prime)\Vert^2
&= \delta \Vert\pi_i(\mathbf{b}_{i+1})\Vert^2 \\
&< \delta \cdot \delta\Vert\pi_i(\mathbf{b}_i)\Vert^2 \\
&\leq \Vert\pi_i(\mathbf{b}_i)\Vert^2 \\
&= \Vert\pi_i(\mathbf{b}_{i+1}^\prime)\Vert^2
\end{aligned}
$$

So after the swap, the condition will hold. We know that swapping columns preserves the lattice, so we can define a second algorithm $\operatorname{ColumnSwap}$ that takes a basis $B$ and transforms it into a second basis of the same lattice that satisfies the second condition of $\delta$-LLL reduced basis:

\begin{algorithm}
\caption{ColumnSwap}
\begin{algorithmic}[1]
    \For{$i \in \{1, 2, \ldots, n-1\}$}
        \If{$\delta\Vert\pi_i(\mathbf{b}_i)\Vert^2 > \Vert \pi_i(\mathbf{b}_{i+1}) \Vert^2$}
            \State $\mathbf{b}_i \leftarrow \mathbf{b}_{i+1}$
            \State $\mathbf{b}_{i+1} \leftarrow \mathbf{b}_{i}$
        \EndIf
    \EndFor
\end{algorithmic}
\end{algorithm}

Unfortunately, after applying $\operatorname{ColumnSwap}$, the first condition no longer holds, so we will need to apply $\operatorname{SizeReduce}$ again. In fact, the LLL basis reduction algorithm is exactly repeatedly alternate between $\operatorname{ColumnSwap}$ and $\operatorname{SizeReduce}$.

\begin{algorithm}
\caption{LLLReduce}
\begin{algorithmic}[1]
    \While{$B$ is not $\delta$-LLL reduced}
        \State $B \leftarrow \operatorname{SizeReduce}(B)$
        \State $B \leftarrow \operatorname{ColumnSwap}(B)$
    \EndWhile
\end{algorithmic}
\end{algorithm}

We can easily see that if $\operatorname{LLLReduce}$ terminates, we will have a correctly reduced basis. It remains to show that $\operatorname{LLLReduce}$ will terminate in polynomial time (at least for when $\delta < 1$.

To prove that $\operatorname{LLLReduce}$ will terminate in polynomial time, we define a positive integer quantity associated with a basis and show that each iteration of $\operatorname{SizeReduce}$ and $\operatorname{ColumnSwap}$ reduce this quantity by $\delta$.

Recall that although determinant is not defined for non-square matrix, it is defined for (sub)lattice generated by sub-basis $B_k = [\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_k] \in \mathbb{Z}^{n \times k}$ where $1 \leq k \leq n$:

$$
\det(\mathcal{L}(B_k)) = \prod_{i=1}^k \Vert \mathbf{b}_i^\ast \Vert = \sqrt{B_k^\intercal B_k}
$$

We define the "potential" of a full-rank basis $B = [\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_n]$ by the product of determinants of sub-lattices generated by sub-basis $B_1, B_2, \ldots, B_n$:

$$
\mathcal{D} = \prod_{k=1}^n \det(\mathcal{L}(B_k))^2
$$

Based on the definition of lattice determinant above, we know that the square of the determinant of a lattice generated by integer basis is an integer, so their products must also be integer. Therefore, $\mathcal{D}$ is an integer.

First observe that in $\operatorname{SizeReduce}$, the basis vector is changed by subtracting a linear combination of basis vectors BEFORE the changed basis vector. This means that after $\operatorname{SizeReduce}$, each of $B_k$ for $1\leq k \leq n$ still generates the same lattice, and the determinant of that lattice remains unchanged. In other words, $\operatorname{SizeReduce}$ does not change the value of $\mathcal{D}$.

Second, for $k < i$, swapping column $\mathbf{b}_i$ with $\mathbf{b}_{i+1}$ does not affect the lattice generated by the partial basis $B_k$ because $B_k = \{\mathbf{b}_1, \ldots, \mathbf{b}_{i-1}\}$ does not contain the swapped columns anyways. On the other hand, for $k > i$, swapping column $\mathbf{b}_i$ with $\mathbf{b}_{i+1}$ also does not affect the lattice generated by the partial basis $B_k$ because it contains BOTH of the swapped column, and swapping column preserves the lattice.

Therefore the only change to $\mathcal{D}$ when swapping $\mathbf{b}_i$ with $\mathbf{b}_{i+1}$ comes from the factor $\det(\mathcal{L}(B_i))$. Denote the potential of the basis $B$ after the swap by $\mathcal{D}^\prime$ then:

$$
\frac{\mathcal{D}}{\mathcal{D}^\prime} = \frac{
    \det(\mathcal{L}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{i-1}, \mathbf{b}_{i}]))^2
}{
    \det(\mathcal{L}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{i-1}, \mathbf{b}_{i+1}]))^2
}
$$

Recall that the determinant of a lattice is the product of the orthogonalized basis vectors. The first $i-1$ terms are identical between the two basis so they all cancel out. The $i$-th term on the numerator is exactly $\mathbf{b}_i^\ast$, while the $i$-th term on the denominator is as follows:

$$
\begin{aligned}
\text{i-th term in denominator} &= \mathbf{b}_{i+1} - \sum_{j < i} \mu_{i+1, j}\mathbf{b}_j^\ast \\
&= \mathbf{b}_{i+1} - (\sum_{1 \leq j \leq n} \mu_{i+1, j}\mathbf{b}_j^\ast  - \sum_{j \geq i} \mu_{i+1, j}\mathbf{b}_j^\ast) \\
&= \mathbf{b}_{i+1} - (\mathbf{b}_{i+1}  - \sum_{j \geq i} \mu_{i+1, j}\mathbf{b}_j^\ast) \\
&= \sum_{j \geq i} \mu_{i+1, j}\mathbf{b}_j^\ast \\
&= \pi_i(\mathbf{b}_{i+1})
\end{aligned}
$$

Therefore we have:

$$
\frac{\mathcal{D}}{\mathcal{D}^\prime} = \frac{
    \det(\mathcal{L}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{i-1}, \mathbf{b}_{i}]))^2
}{
    \det(\mathcal{L}([\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_{i-1}, \mathbf{b}_{i+1}]))^2
} = \frac{\Vert\mathbf{b}_i^\ast\Vert^2}{\Vert\pi_i(\mathbf{b}_{i+1})\Vert^2}
= \frac{\Vert\pi_i(\mathbf{b}_{i})\Vert^2}{\Vert\pi_i(\mathbf{b}_{i+1})\Vert^2}
$$

Because we only swap when $\delta \Vert \pi_i(\mathbf{b}_i) \Vert^2 > \Vert \pi_i(\mathbf{b}_{i+1}) \Vert^2$, the quotient above satisfies:

$$
\frac{\mathcal{D}}{\mathcal{D}^\prime} 
= \frac{\Vert\pi_i(\mathbf{b}_{i})\Vert^2}{\Vert\pi_i(\mathbf{b}_{i+1})\Vert^2}
> \frac{1}{\delta}
$$

Which means that $\mathcal{D}^\prime < \delta \mathcal{D}$. $\blacksquare$
